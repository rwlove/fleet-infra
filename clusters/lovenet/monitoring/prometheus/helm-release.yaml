---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: prometheus
  namespace: monitoring
spec:
  interval: 5m
  chart:
    spec:
      # renovate: registryUrl=https://prometheus-community.github.io/helm-charts
      chart: kube-prometheus-stack
      version: 14.0.1
      sourceRef:
        kind: HelmRepository
        name: prometheus-community-charts
        namespace: flux-system
      interval: 5m
  dependsOn:
  - name: sealed-secrets
    namespace: kube-system
  timeout: 20m
  values:
    prometheusOperator:
      createCustomResource: false
    alertmanager:
      config:
        global:
          resolve_timeout: 5m
        receivers:
        - name: 'null'
        - name: 'webhook'
          webhook_configs:
          - url: "http://192.168.1.35:9000/hooks/webhook-ups"
            send_resolved: false
        route:
          group_by: ['alertname', 'job']
          group_wait: 30s
          group_interval: 5m
          repeat_interval: 6h
          receiver: 'discord'
          routes:
          - receiver: 'null'
            match:
              alertname: Watchdog
          - receiver: 'webhook'
            match:
              alertname: UPS15MinutesRemaining
            continue: true
        inhibit_rules:
        - source_match:
            severity: 'critical'
          target_match:
            severity: 'warning'
          equal: ['alertname', 'namespace']
      ingress:
        enabled: false
      service:
        type: LoadBalancer
        loadBalancerIP: 192.168.6.14
        port:
          port: 9094
      alertmanagerSpec:
        storage:
          volumeClaimTemplate:
            spec:
              storageClassName: "alert-manager-storage-class"
              resources:
                requests:
                  storage: 10Gi
    nodeExporter:
      serviceMonitor:
        relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels:
          - __meta_kubernetes_pod_node_name
          targetLabel: kubernetes_node
    grafana:
      enabled: false
      # image:
      #   repository: grafana/grafana
      #   tag: 7.3.7
      # deploymentStrategy:
      #   type: Recreate
      # persistence:
      #   enabled: false
      #   storageClassName: "rook-ceph-block"
      #   size: 10Gi
      #   accessModes:
      #   - ReadWriteOnce
      # env:
      #   GF_EXPLORE_ENABLED: true
      #   GF_PANELS_DISABLE_SANITIZE_HTML: true
      #   GF_LOG_FILTERS: rendering:debug
      #   VAR_BLOCKY_URL: "http://blocky.kube-system.svc.cluster.local:4000"
      # ingress:
      #   enabled: true
      #   annotations:
      #     kubernetes.io/ingress.class: "external"
      #   hosts:
      #   - "grafana.devbu.io"
      #   tls:
      #   - hosts:
      #     - "grafana.devbu.io"
      # sidecar:
      #   datasources:
      #     enabled: true
      #   dashboards:
      #     enabled: true
      #     searchNamespace: ALL
      # plugins:
      # - natel-discrete-panel
      # - pr0ps-trackmap-panel
      # - grafana-piechart-panel
      # - vonage-status-panel
      # - grafana-worldmap-panel
      # - grafana-clock-panel
      # dashboardProviders:
      #   dashboardproviders.yaml:
      #     apiVersion: 1
      #     providers:
      #     - name: 'default'
      #       orgId: 1
      #       folder: ''
      #       type: file
      #       disableDeletion: false
      #       allowUiUpdates: true
      #       editable: true
      #       options:
      #         path: /var/lib/grafana/dashboards/default
      # dashboards:
      #   default:
      #     # Ref: https://grafana.com/grafana/dashboards/2842
      #     ceph-cluster:
      #       gnetId: 2842
      #       revision: 14
      #       datasource: Prometheus
      #     # Ref: https://grafana.com/grafana/dashboards/5336
      #     ceph-osd:
      #       gnetId: 5336
      #       revision: 5
      #       datasource: Prometheus
      #     # Ref: https://grafana.com/grafana/dashboards/5342
      #     ceph-pools:
      #       gnetId: 5342
      #       revision: 5
      #       datasource: Prometheus
      #     vernemq:
      #       url: https://raw.githubusercontent.com/vernemq/vernemq/master/metrics_scripts/grafana/VerneMQ%20Node%20Metrics.json
      #       datasource: Prometheus
      #     nginx-dashboard:
      #       url: https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/grafana/dashboards/nginx.json
      #       datasource: Prometheus
      #     blocky:
      #       url: https://raw.githubusercontent.com/0xERR0R/blocky/master/docs/blocky-grafana.json
      #       datasource: Prometheus
      #     apc-ups:
      #       url: https://raw.githubusercontent.com/onedr0p/home-operations/main/grafana-dashboards/apc-ups.json
      #       datasource: Prometheus
      #     cyberpower-pdu:
      #       url: https://raw.githubusercontent.com/onedr0p/home-operations/main/grafana-dashboards/cyberpower-pdu.json
      #       datasource: Prometheus
      #     # Ref: https://grafana.com/grafana/dashboards/11315
      #     unifi-client-insights:
      #       gnetId: 11315
      #       revision: 8
      #       datasource: Prometheus
      #     # Ref: https://grafana.com/grafana/dashboards/11311
      #     unifi-network-sites:
      #       gnetId: 11311
      #       revision: 4
      #       datasource: Prometheus
      #     # Ref: https://grafana.com/grafana/dashboards/11314
      #     unifi-uap-insights:
      #       gnetId: 11314
      #       revision: 9
      #       datasource: Prometheus
      #     # Ref: https://grafana.com/grafana/dashboards/11312
      #     unifi-usw-insights:
      #       gnetId: 11312
      #       revision: 8
      #       datasource: Prometheus
      # additionalDataSources:
      # - name: Loki
      #   type: loki
      #   access: proxy
      #   url: http://loki:3100
      # grafana.ini:
      #   paths:
      #     data: /var/lib/grafana/data
      #     logs: /var/log/grafana
      #     plugins: /var/lib/grafana/plugins
      #     provisioning: /etc/grafana/provisioning
      #   analytics:
      #     check_for_updates: true
      #   log:
      #     mode: console
      #   grafana_net:
      #     url: https://grafana.net
    kubeEtcd:
      enabled: false
    # kubeControllerManager:
    #  enabled: false
    #  endpoints:
    #  - 192.168.42.100
    # kubeScheduler:
    #  enabled: false
    #  endpoints:
    #  - 192.168.42.100
    kubeProxy:
      enabled: false
    kubelet:
      serviceMonitor:
        metricRelabelings:
        - action: replace
          sourceLabels:
          - node
          targetLabel: instance
    prometheus:
      ingress:
        enabled: false
        annotations:
          kubernetes.io/ingress.class: "internal"
        hosts:
        - "prometheus.devbu.io"
        tls:
        - hosts:
          - "prometheus.devbu.io"
      service:
        type: LoadBalancer
        loadBalancerIP: 192.168.6.10
        port:
          port: 9090
      prometheusSpec:
        ruleSelector: {}
        ruleNamespaceSelector: {}
        ruleSelectorNilUsesHelmValues: false
        serviceMonitorSelector: {}
        serviceMonitorNamespaceSelector: {}
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelector: {}
        podMonitorNamespaceSelector: {}
        podMonitorSelectorNilUsesHelmValues: false
        retention: 672h
        enableAdminAPI: true
        walCompression: true
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: "prometheus-storage-class"
              resources:
                requests:
                  storage: 50Gi
        # additionalScrapeConfigs:
        #   - job_name: 'node-exporter'
        #     static_configs:
        #     - targets:
        #       # opnsense
        #       - 192.168.1.1:9100
        #       # rocinante nas
        #       - 192.168.1.39:9100
        #       # serenity nas
        #       - 192.168.1.40:9100
        #   - job_name: 'minio'
        #     metrics_path: /minio/prometheus/metrics
        #     static_configs:
        #     - targets:
        #       - 192.168.1.39:9000
  valuesFrom:
  - kind: Secret
    name: "prometheus-helm-values"
